Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08997020870447159
Distance: 8.296967506408691
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.18546199798584
Distance: 8.286937713623047
Next state: tensor([ 4,  2,  0, 17])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 17])
Action: left
Reward: -0.09963386505842209
Distance: 0.0014748870162293315
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09962692111730576
Distance: 0.001108747674152255
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09981196373701096
Distance: 0.0007356700953096151
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10009361803531647
Distance: 0.0005476358928717673
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10036461055278778
Distance: 0.0006412540096789598
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: drop
Reward: -0.10010387003421783
Distance: 0.0010058609768748283
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.10004133731126785
Distance: 0.0011097259121015668
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 1, 0, 0])
Action: end_episode
Reward: -0.10051290690898895
Distance: 0.0011510585900396109
Next state: tensor([1, 1, 0, 0])
================================================================================

