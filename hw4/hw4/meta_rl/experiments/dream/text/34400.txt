Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: 0.044840238988399506
Distance: 9.00428295135498
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.22161158919334412
Distance: 8.859442710876465
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.10360489040613174
Distance: 8.981054306030273
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.11793384701013565
Distance: 8.984659194946289
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.15981826186180115
Distance: 9.002593040466309
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: down
Reward: 8.960274696350098
Distance: 9.062411308288574
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 6
State: tensor([ 4,  2,  0, 16])
Action: drop
Reward: -0.10042933374643326
Distance: 0.0021366386208683252
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 16])
Action: noop
Reward: -0.09931927174329758
Distance: 0.002565971575677395
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 8
State: tensor([ 4,  2,  0, 16])
Action: down
Reward: -0.09918087720870972
Distance: 0.0018852449720725417
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: left
Reward: -0.09988748282194138
Distance: 0.0010661173146218061
Next state: tensor([3, 1, 0, 0])
================================================================================

