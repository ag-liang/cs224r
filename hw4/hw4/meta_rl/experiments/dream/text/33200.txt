Env ID: [15]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.08959446102380753
Distance: 8.85123348236084
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.18914565443992615
Distance: 8.840827941894531
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: 0.0007471069693565369
Distance: 8.929973602294922
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: 0.017742536962032318
Distance: 8.82922649383545
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.0017524734139442444
Distance: 8.7114839553833
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.18876037001609802
Distance: 8.613236427307129
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 3, 0, 0])
Action: down
Reward: 8.597596168518066
Distance: 8.701996803283691
Next state: tensor([ 4,  2,  0, 16])
================================================================================

================================================================================
Timestep: 7
State: tensor([ 4,  2,  0, 16])
Action: up
Reward: -0.09603583812713623
Distance: 0.004399881232529879
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 3, 0, 0])
Action: right
Reward: -0.10031141340732574
Distance: 0.0004357202269602567
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: end_episode
Reward: -0.09992863237857819
Distance: 0.0007471318240277469
Next state: tensor([4, 3, 0, 0])
================================================================================

