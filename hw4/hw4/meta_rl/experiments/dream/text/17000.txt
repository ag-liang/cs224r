Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.2003246247768402
Distance: 8.815690994262695
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.12054882198572159
Distance: 8.916015625
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.82831859588623
Distance: 8.936564445495605
Next state: tensor([ 4,  2,  0, 17])
================================================================================

================================================================================
Timestep: 3
State: tensor([ 4,  2,  0, 17])
Action: up
Reward: -0.09821340441703796
Distance: 0.008245358243584633
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.09884330630302429
Distance: 0.006458763033151627
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.09952691197395325
Distance: 0.005302067846059799
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.09884589910507202
Distance: 0.0048289792612195015
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 4, 0, 0])
Action: up
Reward: -0.10098258405923843
Distance: 0.003674875246360898
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 4, 0, 0])
Action: up
Reward: -0.10108314454555511
Distance: 0.004657458513975143
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 0, 0])
Action: end_episode
Reward: -0.10064409673213959
Distance: 0.005740603897720575
Next state: tensor([3, 4, 0, 0])
================================================================================

