Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.14423713088035583
Distance: 9.482419967651367
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.42564868927002
Distance: 9.526657104492188
Next state: tensor([ 4,  2,  0, 10])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 10])
Action: left
Reward: -0.10033988207578659
Distance: 0.0010079664643853903
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09969989210367203
Distance: 0.0013478476321324706
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09968548268079758
Distance: 0.001047736033797264
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([1, 2, 1, 0])
Action: left
Reward: -0.09992048144340515
Distance: 0.000733215652871877
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([0, 2, 0, 0])
Action: noop
Reward: -0.09988760203123093
Distance: 0.0006536981672979891
Next state: tensor([0, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([0, 2, 0, 0])
Action: down
Reward: -0.10013330727815628
Distance: 0.000541297544259578
Next state: tensor([0, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([0, 1, 0, 0])
Action: down
Reward: -0.10023488104343414
Distance: 0.0006746025756001472
Next state: tensor([0, 0, 1, 0])
================================================================================

