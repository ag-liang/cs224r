Env ID: [11]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1633659303188324
Distance: 9.349160194396973
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.18146094679832458
Distance: 9.41252613067627
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.3052450120449066
Distance: 9.493987083435059
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.2945486009120941
Distance: 9.69923210144043
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: 0.012404821813106537
Distance: 9.893780708312988
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.14451465010643005
Distance: 9.781375885009766
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 3, 1, 0])
Action: up
Reward: -0.013965226709842682
Distance: 9.82589054107666
Next state: tensor([2, 4, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 4, 0, 0])
Action: down
Reward: -0.010769464075565338
Distance: 9.739855766296387
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0])
Action: noop
Reward: -0.0966869369149208
Distance: 9.650625228881836
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 3, 1, 0])
Action: right
Reward: -0.017962075769901276
Distance: 9.64731216430664
Next state: tensor([3, 3, 0, 0])
================================================================================

