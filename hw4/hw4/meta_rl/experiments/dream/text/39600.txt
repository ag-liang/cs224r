Env ID: [21]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.07713756710290909
Distance: 9.453195571899414
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.32970905303955
Distance: 9.430333137512207
Next state: tensor([ 4,  2,  0, 22])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 22])
Action: down
Reward: -0.10001757740974426
Distance: 0.000623346830252558
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.10008739680051804
Distance: 0.0006409210036508739
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.10055951774120331
Distance: 0.0007283163140527904
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.0995696634054184
Distance: 0.0012878312263637781
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.09983924776315689
Distance: 0.0008574934909120202
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.09993784129619598
Distance: 0.0006967417430132627
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.09990105032920837
Distance: 0.000634580384939909
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.10007022321224213
Distance: 0.0005356321344152093
Next state: tensor([4, 1, 0, 0])
================================================================================

