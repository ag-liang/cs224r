Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: drop
Reward: -0.11381778866052628
Distance: 9.858063697814941
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.21801528334617615
Distance: 9.871881484985352
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.03702697902917862
Distance: 9.989896774291992
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.13364562392234802
Distance: 9.926923751831055
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.014705277979373932
Distance: 9.960569381713867
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 1, 1, 0])
Action: up
Reward: -0.14944419264793396
Distance: 9.875274658203125
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.15917548537254333
Distance: 9.924718856811523
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.14686545729637146
Distance: 9.983894348144531
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.917678833007812
Distance: 10.030759811401367
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 2, 0, 8])
Action: up
Reward: -0.09611063450574875
Distance: 0.013080388307571411
Next state: tensor([4, 3, 0, 0])
================================================================================

