Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.060358621180057526
Distance: 10.052278518676758
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.3579011857509613
Distance: 10.0126371383667
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.343144416809082
Distance: 10.270538330078125
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 8])
Action: down
Reward: 0.5026270151138306
Distance: 0.8273937702178955
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: up
Reward: 0.009472452104091644
Distance: 0.22476676106452942
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.11278293281793594
Distance: 0.11529430747032166
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.15320059657096863
Distance: 0.12807723879814148
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: ride_bus
Reward: -0.22363030910491943
Distance: 0.18127784132957458
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.22471186518669128
Distance: 0.3049081563949585
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 0, 0])
Action: left
Reward: -0.19968083500862122
Distance: 0.42962002754211426
Next state: tensor([2, 4, 0, 0])
================================================================================

