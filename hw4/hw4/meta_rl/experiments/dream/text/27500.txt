Env ID: [14]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0756755843758583
Distance: 8.127737998962402
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.00141429901123
Distance: 8.103413581848145
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 15])
Action: left
Reward: -0.09913208335638046
Distance: 0.001998522551730275
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.10133546590805054
Distance: 0.001130605349317193
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 4
State: tensor([ 4,  2,  0, 15])
Action: left
Reward: -0.09959328919649124
Distance: 0.002466066274791956
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09959866106510162
Distance: 0.00205935537815094
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09971197694540024
Distance: 0.0016580154187977314
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.10006637871265411
Distance: 0.0013699934352189302
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 2, 1, 0])
Action: right
Reward: -0.1006874293088913
Distance: 0.0014363734517246485
Next state: tensor([ 4,  2,  0, 15])
================================================================================

================================================================================
Timestep: 9
State: tensor([ 4,  2,  0, 15])
Action: right
Reward: -0.0998111441731453
Distance: 0.002123801503330469
Next state: tensor([ 4,  2,  0, 15])
================================================================================

