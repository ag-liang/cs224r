Env ID: [9]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.02521667629480362
Distance: 6.196269989013672
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.021208859980106354
Distance: 6.121486663818359
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.05071268230676651
Distance: 6.04269552230835
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.06204090267419815
Distance: 5.993408203125
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.05896816402673721
Distance: 5.955449104309082
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.04915056377649307
Distance: 5.914417266845703
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.05934581905603409
Distance: 5.86356782913208
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.1408439576625824
Distance: 5.822913646697998
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.10095367580652237
Distance: 5.863757610321045
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: noop
Reward: -0.0850897803902626
Distance: 5.864711284637451
Next state: tensor([2, 2, 0, 0])
================================================================================

