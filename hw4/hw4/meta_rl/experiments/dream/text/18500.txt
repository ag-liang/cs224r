Env ID: [5]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.08148155361413956
Distance: 8.768348693847656
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1103120818734169
Distance: 8.74983024597168
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.06636104732751846
Distance: 8.76014232635498
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 3, 0, 0])
Action: right
Reward: -0.05516204982995987
Distance: 8.726503372192383
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: pickup
Reward: -0.017937280237674713
Distance: 8.681665420532227
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 3, 0, 0])
Action: down
Reward: 8.489048957824707
Distance: 8.599602699279785
Next state: tensor([4, 2, 0, 6])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 6])
Action: left
Reward: -0.09381131082773209
Distance: 0.010553514584898949
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.09796015173196793
Distance: 0.0043648239225149155
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 2, 0, 0])
Action: ride_bus
Reward: -0.09962120652198792
Distance: 0.0023249746300280094
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.10106149315834045
Distance: 0.0019461787305772305
Next state: tensor([2, 3, 1, 0])
================================================================================

