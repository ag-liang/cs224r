Env ID: [16]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1319032609462738
Distance: 9.120138168334961
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.051505088806152
Distance: 9.1520414352417
Next state: tensor([ 4,  2,  0, 17])
================================================================================

================================================================================
Timestep: 2
State: tensor([ 4,  2,  0, 17])
Action: down
Reward: -0.09993090480566025
Distance: 0.0005357294576242566
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.1001540794968605
Distance: 0.00046663175453431904
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: ride_bus
Reward: -0.10058313608169556
Distance: 0.0006207091500982642
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.09984786808490753
Distance: 0.0012038402492180467
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.09982644766569138
Distance: 0.0010517070768401027
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 1, 0, 0])
Action: noop
Reward: -0.09980408847332001
Distance: 0.0008781516808085144
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.09983869642019272
Distance: 0.0006822362774983048
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 1, 0, 0])
Action: drop
Reward: -0.0998239815235138
Distance: 0.0005209327209740877
Next state: tensor([4, 1, 0, 0])
================================================================================

