Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.0534883514046669
Distance: 9.553293228149414
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.0895753875374794
Distance: 9.506781578063965
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.390832901000977
Distance: 9.496356964111328
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 1])
Action: left
Reward: -0.09796786308288574
Distance: 0.005523261614143848
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: left
Reward: -0.10164931416511536
Distance: 0.003491122741252184
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([2, 2, 0, 0])
Action: left
Reward: -0.09833012521266937
Distance: 0.005140438210219145
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([1, 2, 1, 0])
Action: noop
Reward: -0.10052201896905899
Distance: 0.0034705616999417543
Next state: tensor([1, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([1, 2, 1, 0])
Action: down
Reward: -0.10435091704130173
Distance: 0.00399257754907012
Next state: tensor([1, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([1, 1, 0, 0])
Action: right
Reward: -0.10320422053337097
Distance: 0.008343491703271866
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([2, 1, 1, 0])
Action: down
Reward: -0.11191839724779129
Distance: 0.011547714471817017
Next state: tensor([2, 0, 0, 0])
================================================================================

