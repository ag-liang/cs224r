Env ID: [7]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: up
Reward: -0.03315696865320206
Distance: 9.66313648223877
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 3, 1, 0])
Action: down
Reward: -0.006821252405643463
Distance: 9.596293449401855
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.11180076748132706
Distance: 9.503114700317383
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: right
Reward: 9.413652420043945
Distance: 9.514915466308594
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 2, 0, 8])
Action: right
Reward: -0.1010357216000557
Distance: 0.001263030688278377
Next state: tensor([4, 2, 0, 8])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 2, 0, 8])
Action: left
Reward: -0.099314846098423
Distance: 0.002298749750480056
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.09911122918128967
Distance: 0.0016135959886014462
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.0997491404414177
Distance: 0.0007248266483657062
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: up
Reward: -0.09994837641716003
Distance: 0.00047396571608260274
Next state: tensor([3, 4, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([3, 4, 0, 0])
Action: down
Reward: -0.10015913099050522
Distance: 0.0004223436117172241
Next state: tensor([3, 3, 0, 0])
================================================================================

