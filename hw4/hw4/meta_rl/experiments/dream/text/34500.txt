Env ID: [3]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09170494228601456
Distance: 9.381851196289062
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.10816440731287003
Distance: 9.373556137084961
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.11943302303552628
Distance: 9.381720542907715
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.11051616817712784
Distance: 9.401153564453125
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09975681453943253
Distance: 9.411669731140137
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09648189693689346
Distance: 9.411426544189453
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 2, 1, 0])
Action: noop
Reward: -0.09414253383874893
Distance: 9.40790843963623
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 2, 1, 0])
Action: up
Reward: -0.0447755828499794
Distance: 9.402050971984863
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([3, 3, 0, 0])
Action: right
Reward: 0.0035070404410362244
Distance: 9.346826553344727
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([4, 3, 0, 0])
Action: down
Reward: 9.141698837280273
Distance: 9.243319511413574
Next state: tensor([4, 2, 0, 4])
================================================================================

