Env ID: [1]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: pickup
Reward: -0.09817848354578018
Distance: 8.920515060424805
Next state: tensor([2, 2, 0, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 2, 0, 0])
Action: right
Reward: -0.1214977279305458
Distance: 8.918693542480469
Next state: tensor([3, 2, 1, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 2, 1, 0])
Action: right
Reward: 8.83682918548584
Distance: 8.940191268920898
Next state: tensor([4, 2, 0, 2])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 2, 0, 2])
Action: up
Reward: -0.0987008735537529
Distance: 0.003361788811162114
Next state: tensor([4, 3, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 3, 0, 0])
Action: left
Reward: -0.10034197568893433
Distance: 0.0020626625046133995
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.09944272041320801
Distance: 0.0024046399630606174
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 6
State: tensor([3, 3, 0, 0])
Action: noop
Reward: -0.09997274726629257
Distance: 0.0018473586533218622
Next state: tensor([3, 3, 0, 0])
================================================================================

================================================================================
Timestep: 7
State: tensor([3, 3, 0, 0])
Action: left
Reward: -0.09961427748203278
Distance: 0.0018201059428974986
Next state: tensor([2, 3, 1, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([2, 3, 1, 0])
Action: left
Reward: -0.10164624452590942
Distance: 0.0014343827497214079
Next state: tensor([1, 3, 0, 0])
================================================================================

================================================================================
Timestep: 9
State: tensor([1, 3, 0, 0])
Action: left
Reward: -0.09950865060091019
Distance: 0.0030806236900389194
Next state: tensor([0, 3, 0, 0])
================================================================================

