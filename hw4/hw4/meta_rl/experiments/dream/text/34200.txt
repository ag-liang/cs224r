Env ID: [0]
================================================================================
Timestep: 0
State: tensor([2, 2, 0, 0])
Action: down
Reward: -0.03628597408533096
Distance: 8.839310646057129
Next state: tensor([2, 1, 1, 0])
================================================================================

================================================================================
Timestep: 1
State: tensor([2, 1, 1, 0])
Action: right
Reward: -0.08072338253259659
Distance: 8.775596618652344
Next state: tensor([3, 1, 0, 0])
================================================================================

================================================================================
Timestep: 2
State: tensor([3, 1, 0, 0])
Action: right
Reward: -0.21925029158592224
Distance: 8.756319999694824
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 3
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.0999351516366005
Distance: 8.875570297241211
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 4
State: tensor([4, 1, 0, 0])
Action: right
Reward: -0.09635315090417862
Distance: 8.875505447387695
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 5
State: tensor([4, 1, 0, 0])
Action: up
Reward: 8.76801586151123
Distance: 8.871858596801758
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 6
State: tensor([4, 2, 0, 1])
Action: right
Reward: -0.09743569791316986
Distance: 0.0038426537066698074
Next state: tensor([4, 2, 0, 1])
================================================================================

================================================================================
Timestep: 7
State: tensor([4, 2, 0, 1])
Action: down
Reward: -0.10075824707746506
Distance: 0.0012783503625541925
Next state: tensor([4, 1, 0, 0])
================================================================================

================================================================================
Timestep: 8
State: tensor([4, 1, 0, 0])
Action: end_episode
Reward: -0.09964678436517715
Distance: 0.002036598976701498
Next state: tensor([4, 1, 0, 0])
================================================================================

